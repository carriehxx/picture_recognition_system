"""
å„¿ç«¥äººè„¸è¯†åˆ«ç³»ç»Ÿ - é‡æ„ç‰ˆæœ¬
èŒè´£åˆ†ç¦»ï¼š
- ChildFaceDatabase: è´Ÿè´£æ„å»ºå’Œç®¡ç†å„¿ç«¥äººè„¸æ•°æ®åº“
- ChildFaceRecognizer: è´Ÿè´£æ‰¹é‡è¯†åˆ«å’ŒåŒ¹é…

ä¼˜åŒ–ç‰¹æ€§ï¼š
- ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œäººè„¸åŒ¹é…ï¼ˆæ¯”æ¬§å‡ é‡Œå¾—è·ç¦»æ›´é€‚åˆäººè„¸è¯†åˆ«ï¼‰
- è‡ªé€‚åº”ç›¸ä¼¼åº¦é˜ˆå€¼æ ¹æ®å„¿ç«¥å¹´é¾„è°ƒæ•´
- å¤šæ¨¡å‹ç‰¹å¾èåˆæé«˜è¯†åˆ«å‡†ç¡®æ€§
"""

from facenet_pytorch import MTCNN, InceptionResnetV1
import torch
import numpy as np
import os
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import torch.nn.functional as F
import pickle
import warnings
from typing import Dict, List, Tuple, Optional, Any, Union
import glob
from concurrent.futures import ThreadPoolExecutor
import multiprocessing
from dataclasses import dataclass
import shutil
from datetime import datetime, timedelta
import json
import cv2
from collections import defaultdict
import logging
import functools
import gc

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

warnings.filterwarnings('ignore', category=FutureWarning)

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f'ä½¿ç”¨è®¾å¤‡: {device}')

CHILD_CONFIG = {
    # MTCNN å‚æ•°
    'mtcnn': {
        'image_size': 160,
        'margin': 30,
        'min_face_size': 25,
        'thresholds': [0.4, 0.4, 0.4],  # é™ä½é˜ˆå€¼ï¼Œæé«˜å„¿ç«¥äººè„¸æ£€æµ‹ç‡
        'factor': 0.709,                  # é™ä½ç¼©æ”¾å› å­ï¼Œæ£€æµ‹æ›´å°çš„äººè„¸
        'keep_all': True,
        'post_process': True
    },
    
    # è¯†åˆ«å‚æ•° 
    'recognition': {
        'default_threshold': 0.55,  # ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼
        'quality_threshold': 0.6,
        'min_face_size': 60,
        'max_age_days': 180,
    },
    
    # è´¨é‡è¯„ä¼°
    'quality': {
        'min_face_size': 60,
        'max_blur_variance': 120,
        'min_brightness': 40,
        'max_brightness': 220,
        'pose_threshold': 35,
        'expression_tolerance': 0.8
    },
    
    # å¹´é¾„åˆ†ç»„é˜ˆå€¼ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    'age_thresholds': {
        'infant': (0, 2, 0.65),      # å©´å„¿æœŸï¼Œç›¸ä¼¼åº¦é˜ˆå€¼0.65ï¼ˆæœ€ä¸¥æ ¼ï¼‰
        'toddler': (2, 5, 0.6),      # å¹¼å„¿æœŸï¼Œç›¸ä¼¼åº¦é˜ˆå€¼0.6
        'child': (5, 10, 0.55),      # å„¿ç«¥æœŸï¼Œç›¸ä¼¼åº¦é˜ˆå€¼0.55
        'preteen': (10, 13, 0.5)     # é’æ˜¥æœŸå‰ï¼Œç›¸ä¼¼åº¦é˜ˆå€¼0.5ï¼ˆæœ€å®½æ¾ï¼‰
    }
}

@dataclass
class ChildProfile:
    """å„¿ç«¥æ¡£æ¡ˆä¿¡æ¯"""
    student_id: int  # å­¦å·ï¼Œä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
    name: str        # å§“åï¼Œç”¨äºæ˜¾ç¤º
    age: int         # å¹´é¾„
    class_id: int    # ç­çº§ID

@dataclass
class FaceQualityResult:
    """äººè„¸è´¨é‡è¯„ä¼°ç»“æœ"""
    quality_score: float
    confidence: float
    face_size: Tuple[int, int]
    brightness: float
    blur_variance: float
    pose_angle: float
    issues: List[str]
    is_suitable_for_children: bool

class ChildFaceDatabase:
    """
    å„¿ç«¥äººè„¸æ•°æ®åº“ç®¡ç†ç±»
    èŒè´£ï¼š
    1. å»ºç«‹å’Œè°ƒå–æ•°æ®åº“
    2. è¯»å–æ•°æ®åº“ä¿¡æ¯
    3. æ·»åŠ æ–°çš„å„¿ç«¥ï¼ˆé€šè¿‡è¯†åˆ«å›¾ç‰‡ä¸­æœ€é«˜ç½®ä¿¡åº¦çš„äººè„¸ï¼‰
    4. å­˜å‚¨æ–°çš„å„¿ç«¥äººè„¸æ•°æ®
    """
    
    def __init__(self, storage_path: str = "storage", 
                 database_path: str = "face_database.pkl",
                 profiles_path: str = "child_profiles.json",
                 enable_db_integration: bool = True):
        """
        åˆå§‹åŒ–å„¿ç«¥äººè„¸æ•°æ®åº“
        
        Args:
            storage_path: å„¿ç«¥ç…§ç‰‡å­˜å‚¨è·¯å¾„
            database_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            profiles_path: å„¿ç«¥æ¡£æ¡ˆæ–‡ä»¶è·¯å¾„
            enable_db_integration: æ˜¯å¦å¯ç”¨æ•°æ®åº“é›†æˆï¼ˆMySQLï¼‰
        """
        self.storage_path = storage_path
        self.database_path = os.path.join('results', database_path)
        self.profiles_path = os.path.join('results', profiles_path)
        
        # åˆå§‹åŒ–æ•°æ®åº“é›†æˆ
        self.db_integration = None
        if enable_db_integration:
            try:
                from database_integration import ChildFaceDatabaseIntegration
                self.db_integration = ChildFaceDatabaseIntegration()
                logger.info("âœ… æ•°æ®åº“é›†æˆæ¨¡å—å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"âš ï¸ æ•°æ®åº“é›†æˆæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
                logger.warning("å°†ä½¿ç”¨æœ¬åœ°å­˜å‚¨æ¨¡å¼")
        
        # åˆå§‹åŒ–äººè„¸æ£€æµ‹å’Œç‰¹å¾æå–æ¨¡å‹
        self._init_models()
        
        # æ•°æ®å­˜å‚¨
        self.face_embeddings: Dict[int, Dict] = {}  # {student_id: {embedding, metadata}}
        self.child_profiles: Dict[int, ChildProfile] = {}  # {student_id: ChildProfile}
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self._ensure_directories_exist()
        
        # åŠ è½½æ•°æ®åº“
        self.load_database()
        self.load_profiles()
        
        logger.info(f"å„¿ç«¥äººè„¸æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼Œå½“å‰æœ‰ {len(self.face_embeddings)} ä¸ªå„¿ç«¥æ¡£æ¡ˆ")
    
    def _init_models(self):
        """åˆå§‹åŒ–äººè„¸æ£€æµ‹å’Œç‰¹å¾æå–æ¨¡å‹"""
        mtcnn_config = CHILD_CONFIG['mtcnn']
        self.mtcnn = MTCNN(
            image_size=mtcnn_config['image_size'],
            margin=mtcnn_config['margin'],
            min_face_size=mtcnn_config['min_face_size'],
            thresholds=mtcnn_config['thresholds'],
            factor=mtcnn_config['factor'],
            keep_all=mtcnn_config['keep_all'],
            post_process=mtcnn_config['post_process'],
            device=device
        )
        
        # ä½¿ç”¨å¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé›†æˆ
        self.models = {
            'vggface2': InceptionResnetV1(pretrained='vggface2').eval().to(device),
            'casia': InceptionResnetV1(pretrained='casia-webface').eval().to(device)
        }
    
    def _ensure_directories_exist(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦ç›®å½•å­˜åœ¨"""
        directories = [
            self.storage_path,
            os.path.join(self.storage_path, "active"),
            os.path.join(self.storage_path, "archived"),
            "results",
            "logs"
        ]
        
        for directory in directories:
            if not os.path.exists(directory):
                os.makedirs(directory)
                logger.info(f"åˆ›å»ºç›®å½•: {directory}")
    
    def evaluate_child_face_quality(self, img_path: str, face_tensor: torch.Tensor, 
                                  box: np.ndarray, prob: float) -> FaceQualityResult:
        """è¯„ä¼°å„¿ç«¥äººè„¸è´¨é‡"""
        config = CHILD_CONFIG['quality']
        quality_score = 0.0
        issues = []
        
        # 1. æ£€æµ‹ç½®ä¿¡åº¦è¯„ä¼°
        if prob < 0.6:
            issues.append(f"æ£€æµ‹ç½®ä¿¡åº¦åä½: {prob:.3f}")
        else:
            quality_score += 0.25
        
        # 2. äººè„¸å°ºå¯¸è¯„ä¼°
        face_width = box[2] - box[0] if box is not None else 0
        face_height = box[3] - box[1] if box is not None else 0
        min_size = min(face_width, face_height)
        
        if min_size < config['min_face_size']:
            issues.append(f"äººè„¸å°ºå¯¸è¿‡å°: {min_size:.1f}px")
        elif min_size > 80:
            quality_score += 0.25
        else:
            quality_score += 0.15
        
        # 3. å›¾åƒæ¸…æ™°åº¦è¯„ä¼°
        blur_variance = 0
        try:
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                blur_variance = cv2.Laplacian(img, cv2.CV_64F).var()
                if blur_variance < config['max_blur_variance']:
                    issues.append(f"å›¾åƒæ¨¡ç³Š: {blur_variance:.1f}")
                else:
                    quality_score += 0.20
        except Exception as e:
            logger.warning(f"æ— æ³•è®¡ç®—æ¨¡ç³Šåº¦: {e}")
        
        # 4. äº®åº¦è¯„ä¼°
        brightness = float(torch.mean(face_tensor))
        if brightness < config['min_brightness'] or brightness > config['max_brightness']:
            issues.append(f"äº®åº¦ä¸é€‚å®œ: {brightness:.1f}")
        else:
            quality_score += 0.15
        
        # 5. å§¿æ€è¯„ä¼°
        pose_angle = self._estimate_pose_angle(box)
        if pose_angle > config['pose_threshold']:
            issues.append(f"å§¿æ€åå·®è¿‡å¤§: {pose_angle:.1f}Â°")
        else:
            quality_score += 0.15
        
        # å„¿ç«¥ç‰¹æ®Šé€‚åº”æ€§æ£€æŸ¥
        is_suitable_for_children = (
            len(issues) <= 2 and
            quality_score >= 0.5 and
            min_size >= config['min_face_size']
        )
        
        return FaceQualityResult(
            quality_score=quality_score,
            confidence=prob,
            face_size=(int(face_width), int(face_height)),
            brightness=brightness,
            blur_variance=blur_variance,
            pose_angle=pose_angle,
            issues=issues,
            is_suitable_for_children=is_suitable_for_children
        )
    
    def _estimate_pose_angle(self, box: np.ndarray) -> float:
        """ä¼°ç®—äººè„¸å§¿æ€è§’åº¦"""
        if box is None:
            return 0.0
        
        width = box[2] - box[0]
        height = box[3] - box[1]
        aspect_ratio = width / height
        
        normal_ratio = 0.75
        deviation = abs(aspect_ratio - normal_ratio)
        estimated_angle = min(deviation * 60, 45)
        
        return estimated_angle
    
    def extract_best_face_embedding(self, img_path: str) -> Tuple[Optional[torch.Tensor], FaceQualityResult]:
        """
        æå–å›¾ç‰‡ä¸­æœ€ä½³äººè„¸ç‰¹å¾ï¼ˆç”¨äºæ„å»ºæ•°æ®åº“ï¼‰
        
        Args:
            img_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            Tuple[embedding, quality_result]: ç‰¹å¾å‘é‡å’Œè´¨é‡è¯„ä¼°ç»“æœ
        """
        try:
            img = Image.open(img_path).convert('RGB')
            boxes, probs = self.mtcnn.detect(img)
            
            if boxes is None or len(boxes) == 0:
                logger.warning(f"æœªæ£€æµ‹åˆ°äººè„¸: {img_path}")
                return None, FaceQualityResult(0, 0, (0, 0), 0, 0, 0, ["æœªæ£€æµ‹åˆ°äººè„¸"], False)
            
            # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„äººè„¸
            best_idx = np.argmax(probs)
            box = boxes[best_idx]
            prob = probs[best_idx]
            
            # æå–äººè„¸
            face_tensor = self.mtcnn.extract(img, [box], save_path=None)
            if face_tensor is None or len(face_tensor) == 0:
                logger.warning(f"äººè„¸æå–å¤±è´¥: {img_path}")
                return None, FaceQualityResult(0, prob, (0, 0), 0, 0, 0, ["äººè„¸æå–å¤±è´¥"], False)
            
            face_tensor = face_tensor[0].unsqueeze(0).to(device)
            
            # è´¨é‡è¯„ä¼°
            quality_result = self.evaluate_child_face_quality(img_path, face_tensor, box, prob)
            
            # å¦‚æœè´¨é‡ä¸é€‚åˆå„¿ç«¥è¯†åˆ«ï¼Œè¿”å›None
            if not quality_result.is_suitable_for_children:
                logger.warning(f"äººè„¸è´¨é‡ä¸é€‚åˆå„¿ç«¥è¯†åˆ«: {img_path}, é—®é¢˜: {quality_result.issues}")
                return None, quality_result
            
            # å¤šæ¨¡å‹ç‰¹å¾æå–å’Œèåˆ
            embeddings = []
            for model_name, model in self.models.items():
                with torch.no_grad():
                    embedding = model(face_tensor)
                    embedding = F.normalize(embedding, p=2, dim=1)
                    embeddings.append(embedding)
            
            # ç‰¹å¾èåˆï¼ˆåŠ æƒå¹³å‡ï¼‰
            weights = [1, 0]  # vggface2æƒé‡æ›´é«˜ï¼Œå¯¹å„¿ç«¥æ•ˆæœæ›´å¥½
            final_embedding = sum(w * emb for w, emb in zip(weights, embeddings))
            final_embedding = F.normalize(final_embedding, p=2, dim=1)
            
            logger.info(f"æˆåŠŸæå–å„¿ç«¥äººè„¸ç‰¹å¾: {img_path}, è´¨é‡åˆ†æ•°: {quality_result.quality_score:.2f}")
            return final_embedding.cpu(), quality_result
            
        except Exception as e:
            logger.error(f"æå–äººè„¸ç‰¹å¾æ—¶å‡ºé”™: {img_path}, é”™è¯¯: {e}")
            return None, FaceQualityResult(0, 0, (0, 0), 0, 0, 0, [f"å¤„ç†é”™è¯¯: {str(e)}"], False)
    
    def add_child(self, img_paths: Union[str, List[str]], child_profile: ChildProfile, 
                  update_if_exists: bool = True) -> bool:
        """
        æ·»åŠ æ–°å„¿ç«¥åˆ°æ•°æ®åº“
        
        Args:
            img_paths: å›¾ç‰‡è·¯å¾„ï¼ˆå•å¼ æˆ–å¤šå¼ ï¼‰
            child_profile: å„¿ç«¥æ¡£æ¡ˆä¿¡æ¯
            update_if_exists: å¦‚æœå·²å­˜åœ¨æ˜¯å¦æ›´æ–°
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        if isinstance(img_paths, str):
            img_paths = [img_paths]
        
        student_id = child_profile.student_id
        child_name = child_profile.name
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if student_id in self.face_embeddings and not update_if_exists:
            logger.warning(f"å­¦ç”Ÿ {child_name}({student_id}) å·²å­˜åœ¨ï¼Œè®¾ç½® update_if_exists=True æ¥æ›´æ–°")
            return False
        
        logger.info(f"æ·»åŠ å„¿ç«¥: {child_name}({student_id})ï¼Œç…§ç‰‡æ•°é‡: {len(img_paths)}")
        
        embeddings = []
        quality_scores = []
        
        # å¤„ç†æ‰€æœ‰ç…§ç‰‡ï¼Œæå–æœ€ä½³äººè„¸
        for img_path in img_paths:
            if not os.path.exists(img_path):
                logger.warning(f"å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
                continue
            
            embedding, quality_result = self.extract_best_face_embedding(img_path)
            
            if embedding is not None:
                embeddings.append(embedding)
                quality_scores.append(quality_result.quality_score)
                logger.info(f"âœ… æˆåŠŸå¤„ç†ç…§ç‰‡: {img_path}")
            else:
                logger.warning(f"âŒ ç…§ç‰‡å¤„ç†å¤±è´¥: {img_path}")
        
        if not embeddings:
            logger.error(f"æ²¡æœ‰æˆåŠŸå¤„ç†çš„ç…§ç‰‡ï¼Œæ— æ³•æ·»åŠ å„¿ç«¥: {child_name}({student_id})")
            return False
        
        # ç‰¹å¾èåˆï¼ˆå–å¹³å‡ï¼‰
        if len(embeddings) == 1:
            final_embedding = embeddings[0]
        else:
            # æ ¹æ®è´¨é‡åˆ†æ•°åŠ æƒå¹³å‡
            weights = torch.tensor(quality_scores, dtype=torch.float32)
            weights = weights / weights.sum()  # å½’ä¸€åŒ–
            
            weighted_embeddings = []
            for i, embedding in enumerate(embeddings):
                weighted_embeddings.append(embedding * weights[i])
            
            final_embedding = torch.stack(weighted_embeddings).sum(dim=0)
            final_embedding = F.normalize(final_embedding, p=2, dim=1)
        
        # ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“
        self.face_embeddings[student_id] = {
            'embedding': final_embedding,
            'profile': child_profile,
            'created_at': datetime.now().isoformat(),
            'last_updated': datetime.now().isoformat(),
            'photos_count': len(embeddings),
            'avg_quality': np.mean(quality_scores),
            'update_due_date': (datetime.now() + timedelta(days=30)).isoformat()
        }
        
        self.child_profiles[student_id] = child_profile
        
        # ä¿å­˜åˆ°MySQLæ•°æ®åº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.db_integration:
            try:
                self.db_integration.save_face_embedding(
                    student_id,
                    final_embedding,
                    len(embeddings),
                    np.mean(quality_scores),
                    self.get_adaptive_threshold(student_id)
                )
                logger.info(f"âœ… å„¿ç«¥æ•°æ®å·²ä¿å­˜åˆ°MySQLæ•°æ®åº“: {student_id}")
            except Exception as e:
                logger.warning(f"ä¿å­˜åˆ°MySQLæ•°æ®åº“å¤±è´¥: {e}")
        
        # è‡ªåŠ¨ä¿å­˜æœ¬åœ°æ•°æ®åº“
        self.save_database()
        self.save_profiles()
        
        logger.info(f"âœ… æˆåŠŸæ·»åŠ å„¿ç«¥ {child_name}({student_id})ï¼Œå¹³å‡è´¨é‡åˆ†æ•°: {np.mean(quality_scores):.2f}")
        return True
    
    def get_adaptive_threshold(self, student_id: int) -> float:
        """æ ¹æ®å„¿ç«¥å¹´é¾„è·å–è‡ªé€‚åº”è¯†åˆ«é˜ˆå€¼"""
        if student_id not in self.child_profiles:
            return CHILD_CONFIG['recognition']['default_threshold']
        
        age = self.child_profiles[student_id].age
        
        # æ ¹æ®å¹´é¾„ç»„ç¡®å®šé˜ˆå€¼
        for group_name, (min_age, max_age, threshold) in CHILD_CONFIG['age_thresholds'].items():
            if min_age <= age < max_age:
                return threshold
        
        return CHILD_CONFIG['recognition']['default_threshold']
    
    def get_children_statistics(self) -> Dict:
        """è·å–å„¿ç«¥æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_children': len(self.face_embeddings),
            'age_distribution': defaultdict(int),
            'quality_distribution': {'high': 0, 'medium': 0, 'low': 0},
            'update_required': len(self.check_update_requirements()),
            'avg_photos_per_child': 0
        }
        
        if not self.face_embeddings:
            return stats
        
        total_photos = 0
        quality_scores = []
        
        for student_id, data in self.face_embeddings.items():
            # å¹´é¾„åˆ†å¸ƒ
            if student_id in self.child_profiles:
                age = self.child_profiles[student_id].age
                if age <= 3:
                    stats['age_distribution']['0-3å²'] += 1
                elif age <= 6:
                    stats['age_distribution']['4-6å²'] += 1
                elif age <= 10:
                    stats['age_distribution']['7-10å²'] += 1
                else:
                    stats['age_distribution']['11å²ä»¥ä¸Š'] += 1
            
            # ç…§ç‰‡ç»Ÿè®¡
            total_photos += data.get('photos_count', 1)
            
            # è´¨é‡åˆ†å¸ƒ
            quality = data.get('avg_quality', 0)
            quality_scores.append(quality)
            if quality >= 0.8:
                stats['quality_distribution']['high'] += 1
            elif quality >= 0.6:
                stats['quality_distribution']['medium'] += 1
            else:
                stats['quality_distribution']['low'] += 1
        
        stats['avg_photos_per_child'] = total_photos / len(self.face_embeddings)
        stats['avg_quality_score'] = np.mean(quality_scores) if quality_scores else 0
        
        return stats
    
    def check_update_requirements(self) -> List[int]:
        """æ£€æŸ¥éœ€è¦æ›´æ–°ç…§ç‰‡çš„å„¿ç«¥"""
        need_update = []
        current_time = datetime.now()
        
        for student_id, data in self.face_embeddings.items():
            update_due_date = datetime.fromisoformat(data.get('update_due_date', current_time.isoformat()))
            if current_time >= update_due_date:
                need_update.append(student_id)
        
        return need_update
    
    def save_database(self):
        """ä¿å­˜æ•°æ®åº“"""
        try:
            with open(self.database_path, 'wb') as f:
                pickle.dump({
                    'face_embeddings': self.face_embeddings,
                    'version': '2.0_child_optimized',
                    'saved_at': datetime.now().isoformat()
                }, f)
            logger.info(f"æ•°æ®åº“å·²ä¿å­˜: {self.database_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®åº“å¤±è´¥: {e}")
    
    def load_database(self):
        """åŠ è½½æ•°æ®åº“"""
        try:
            if os.path.exists(self.database_path):
                with open(self.database_path, 'rb') as f:
                    data = pickle.load(f)
                    self.face_embeddings = data.get('face_embeddings', {})
                    logger.info(f"æ•°æ®åº“å·²åŠ è½½: {len(self.face_embeddings)} ä¸ªå„¿ç«¥æ¡£æ¡ˆ")
        except Exception as e:
            logger.error(f"åŠ è½½æ•°æ®åº“å¤±è´¥: {e}")
            self.face_embeddings = {}
    
    def save_profiles(self):
        """ä¿å­˜å„¿ç«¥æ¡£æ¡ˆ"""
        try:
            profiles_data = {}
            for student_id, profile in self.child_profiles.items():
                # è¿™é‡Œä½¿ç”¨å­—ç¬¦ä¸²é”®æ˜¯å› ä¸ºJSONè§„èŒƒè¦æ±‚å­—å…¸çš„keyå¿…é¡»ä¸ºå­—ç¬¦ä¸²ç±»å‹ã€‚
                # å¦‚æœç”¨intç±»å‹ï¼Œjson.dumpä¼šè‡ªåŠ¨è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œè¯»å–æ—¶éœ€è¦æ³¨æ„è½¬æ¢å›intã€‚
                # åªè¦åœ¨load_profilesæ—¶åšç±»å‹è½¬æ¢ï¼ˆå¦‚int(student_id)ï¼‰ï¼Œä¸ä¼šæœ‰é—®é¢˜ã€‚
                profiles_data[str(student_id)] = {
                    'student_id': int(student_id),
                    'name': profile.name,
                    'age': profile.age,
                    'class_id': profile.class_id
                }
            
            with open(self.profiles_path, 'w', encoding='utf-8') as f:
                json.dump(profiles_data, f, ensure_ascii=False, indent=2)
            logger.info(f"å„¿ç«¥æ¡£æ¡ˆå·²ä¿å­˜: {self.profiles_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜å„¿ç«¥æ¡£æ¡ˆå¤±è´¥: {e}")
    
    def delete_child(self, student_id: int):
        """åˆ é™¤å„¿ç«¥"""
        if student_id in self.face_embeddings:
            del self.face_embeddings[student_id]
            del self.child_profiles[student_id]
            self.save_database()
            self.save_profiles()
            # åœ¨æ•°æ®åº“ä¸­ç§»é™¤è¿™ä¸ªå­¦ç”Ÿçš„embeddingï¼Œåˆ é™¤å…³äºè¿™ä¸ªå­¦ç”Ÿçš„åŒ¹é…è®°å½•
            # è¿™ä¸ªé‡æ–°è€ƒè™‘ä¸€ä¸‹recognize dataçš„é€»è¾‘ï¼Œå› ä¸ºé‡Œé¢åŒ…å«äº†è¯†åˆ«çš„childçš„ä¿¡æ¯ï¼Œä½†å…¶å®æ²¡å¿…è¦
    
    def load_profiles(self):
        """åŠ è½½å„¿ç«¥æ¡£æ¡ˆ"""
        try:
            if os.path.exists(self.profiles_path):
                with open(self.profiles_path, 'r', encoding='utf-8') as f:
                    profiles_data = json.load(f)
                    
                for student_id, data in profiles_data.items():
                    if 'student_id' not in data:
                        data['student_id'] = int(student_id)
                    
                    # ç¡®ä¿ student_id æ˜¯æ•´æ•°ç±»å‹
                    student_id_int = int(student_id) 
                    profile_data = {
                        'student_id': student_id_int,
                        'name': data.get('name', 'Unknown'),
                        'age': data.get('age', 0),
                        'class_id': data.get('class_id', 0)
                    }
                    self.child_profiles[student_id_int] = ChildProfile(**profile_data)
                logger.info(f"å„¿ç«¥æ¡£æ¡ˆå·²åŠ è½½: {len(self.child_profiles)} ä¸ªæ¡£æ¡ˆ")
        except Exception as e:
            logger.error(f"åŠ è½½å„¿ç«¥æ¡£æ¡ˆå¤±è´¥: {e}")
            self.child_profiles = {}

class ChildFaceRecognizer:
    """
    å„¿ç«¥äººè„¸è¯†åˆ«å™¨
    èŒè´£ï¼š
    1. æ›´æ–°æ•°æ®ç¼“å­˜
    2. å¹¶è¡Œå¤„ç†æ‰¹é‡å›¾ç‰‡
    3. æ£€æµ‹å›¾ç‰‡ä¸­çš„æ‰€æœ‰äººè„¸
    4. è¯†åˆ«æ‰€æœ‰äººè„¸
    5. è¯†åˆ«æˆåŠŸçš„å›¾ç‰‡å­˜åˆ°OSS
    6. å­˜å‚¨æ•°æ®åˆ°æ•°æ®åº“
    """
    
    def __init__(self, face_database: ChildFaceDatabase, global_threshold: float = None):
        """
        åˆå§‹åŒ–å„¿ç«¥äººè„¸è¯†åˆ«å™¨
        
        Args:
            face_database: å„¿ç«¥äººè„¸æ•°æ®åº“
            global_threshold: å…¨å±€é˜ˆå€¼ï¼ˆå¦‚æœä¸è®¾ç½®åˆ™ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼‰
        """
        self.face_database = face_database
        self.global_threshold = global_threshold
        self._embedding_cache = {}   # ç‰¹å¾å‘é‡ç¼“å­˜
        self._last_cache_update = datetime.now()
        
        logger.info(f"å„¿ç«¥äººè„¸è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®åº“åŒ…å« {len(face_database.face_embeddings)} ä¸ªå„¿ç«¥")
    
    def _update_embedding_cache(self):
        """æ›´æ–°ç‰¹å¾å‘é‡ç¼“å­˜ä»¥æé«˜è¯†åˆ«é€Ÿåº¦"""
        current_time = datetime.now()
        should_update = (
            len(self._embedding_cache) == 0 or
            (current_time - self._last_cache_update).seconds > 300
        )
        
        if should_update:
            self._embedding_cache.clear()
            for student_id, data in self.face_database.face_embeddings.items():
                embedding = data['embedding']
                
                # ç¡®ä¿ç‰¹å¾å‘é‡ç»´åº¦æ­£ç¡® (åº”è¯¥æ˜¯ [1, 512])
                if embedding.dim() == 3:  # [1, 1, 512]
                    embedding = embedding.squeeze(0)  # å˜æˆ [1, 512]
                elif embedding.dim() == 1:  # [512]
                    embedding = embedding.unsqueeze(0)  # å˜æˆ [1, 512]
                
                # éªŒè¯ç»´åº¦
                if embedding.size(1) != 512:
                    logger.warning(f"å­¦ç”Ÿ {student_id} çš„ç‰¹å¾å‘é‡ç»´åº¦å¼‚å¸¸: {embedding.size()}")
                    continue
                
                self._embedding_cache[student_id] = embedding
            
            self._last_cache_update = current_time
            logger.info(f"ç‰¹å¾å‘é‡ç¼“å­˜å·²æ›´æ–°ï¼ŒåŒ…å« {len(self._embedding_cache)} ä¸ªå­¦ç”Ÿ")
        else:
            logger.debug(f"ç¼“å­˜æ— éœ€æ›´æ–°ï¼Œå½“å‰åŒ…å« {len(self._embedding_cache)} ä¸ªå­¦ç”Ÿ")
    
    def extract_all_faces_for_recognition(self, img_path: str) -> List[Tuple[torch.Tensor, FaceQualityResult, np.ndarray, float]]:
        """
        æå–å›¾ç‰‡ä¸­æ‰€æœ‰äººè„¸ç‰¹å¾ï¼ˆç”¨äºè¯†åˆ«ï¼‰
        
        Args:
            img_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            List[Tuple[embedding, quality_result, box, prob]]: æ‰€æœ‰äººè„¸çš„ç‰¹å¾å‘é‡ã€è´¨é‡è¯„ä¼°ã€è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦
        """
        try:
            img = Image.open(img_path).convert('RGB')
            boxes, probs = self.face_database.mtcnn.detect(img)
            
            if boxes is None or len(boxes) == 0:
                logger.warning(f"æœªæ£€æµ‹åˆ°äººè„¸: {img_path}")
                return []
            
            results = []
            
            # å¤„ç†æ‰€æœ‰æ£€æµ‹åˆ°çš„äººè„¸
            for i, (box, prob) in enumerate(zip(boxes, probs)):
                try:
                    # æå–äººè„¸
                    face_tensor = self.face_database.mtcnn.extract(img, [box], save_path=None)
                    if face_tensor is None or len(face_tensor) == 0:
                        logger.warning(f"äººè„¸ {i+1} æå–å¤±è´¥: {img_path}")
                        continue
                    
                    face_tensor = face_tensor[0].unsqueeze(0).to(device)
                    
                    # è´¨é‡è¯„ä¼°ï¼ˆè¯†åˆ«æ—¶æ”¾å®½è´¨é‡è¦æ±‚ï¼‰
                    quality_result = self.face_database.evaluate_child_face_quality(img_path, face_tensor, box, prob)
                    
                    # å¯¹äºè¯†åˆ«ï¼Œæˆ‘ä»¬æ¥å—è´¨é‡è¾ƒä½çš„äººè„¸ï¼Œä½†è®°å½•è´¨é‡ä¿¡æ¯
                    if quality_result.quality_score < 0.3:  # è´¨é‡å¤ªå·®çš„äººè„¸è·³è¿‡
                        logger.warning(f"äººè„¸ {i+1} è´¨é‡è¿‡ä½ï¼Œè·³è¿‡: {img_path}, è´¨é‡åˆ†æ•°: {quality_result.quality_score:.2f}")
                        continue
                    
                    # å¤šæ¨¡å‹ç‰¹å¾æå–å’Œèåˆ
                    embeddings = []
                    for model_name, model in self.face_database.models.items():
                        with torch.no_grad():
                            embedding = model(face_tensor)
                            embedding = F.normalize(embedding, p=2, dim=1)
                            embeddings.append(embedding)
                    
                    # ç‰¹å¾èåˆï¼ˆåŠ æƒå¹³å‡ï¼‰
                    weights = [1, 0]  # vggface2æƒé‡æ›´é«˜ï¼Œå¯¹å„¿ç«¥æ•ˆæœæ›´å¥½
                    final_embedding = sum(w * emb for w, emb in zip(weights, embeddings))
                    final_embedding = F.normalize(final_embedding, p=2, dim=1)
                    
                    results.append((final_embedding.cpu(), quality_result, box, prob))
                    logger.info(f"æˆåŠŸæå–äººè„¸ {i+1} ç‰¹å¾: {img_path}, è´¨é‡åˆ†æ•°: {quality_result.quality_score:.2f}, ç½®ä¿¡åº¦: {prob:.3f}")
                    
                except Exception as e:
                    logger.error(f"å¤„ç†äººè„¸ {i+1} æ—¶å‡ºé”™: {img_path}, é”™è¯¯: {e}")
                    continue
            
            logger.info(f"å›¾ç‰‡ {img_path} å…±æ£€æµ‹åˆ° {len(boxes)} å¼ äººè„¸ï¼ŒæˆåŠŸæå– {len(results)} å¼ äººè„¸ç‰¹å¾")
            return results
            
        except Exception as e:
            logger.error(f"æå–æ‰€æœ‰äººè„¸ç‰¹å¾æ—¶å‡ºé”™: {img_path}, é”™è¯¯: {e}")
            return []

    def recognize_all_faces_in_image(self, img_path: str, use_adaptive_threshold: bool = True) -> List[Tuple[int, float, Dict]]:
        """
        è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰è„¸
        
        Args:
            img_path: å¾…è¯†åˆ«å›¾ç‰‡è·¯å¾„
            use_adaptive_threshold: æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
            
        Returns:
            List[Tuple[int, confidence, details]]: æ‰€æœ‰äººè„¸çš„è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        if not self.face_database.face_embeddings:
            return [(-1, 0.0, {"error": "æ•°æ®åº“ä¸ºç©º"})]
        
        # æ›´æ–°ç¼“å­˜
        self._update_embedding_cache()
        
        # è¾“å…¥éªŒè¯
        if not os.path.exists(img_path):
            return [(-1, 0.0, {"error": f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}"})]
        
        try:
            # æå–å¾…è¯†åˆ«å›¾ç‰‡ä¸­æ‰€æœ‰äººè„¸ç‰¹å¾
            face_results = self.extract_all_faces_for_recognition(img_path)
            
            if not face_results:
                return [(-1, 0.0, {
                    "error": "æ— æ³•æå–äººè„¸ç‰¹å¾",
                    "image_path": img_path
                })]
            
            # ç¡®ä¿ç¼“å­˜å·²å¡«å……
            if len(self._embedding_cache) == 0:
                logger.warning("ç¼“å­˜ä¸ºç©ºï¼Œå¯èƒ½æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®")
                return [(-1, 0.0, {"error": "äººè„¸æ•°æ®åº“ç¼“å­˜ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ å­¦ç”Ÿæ•°æ®"})]
            
            # ä½¿ç”¨ç¼“å­˜è¿›è¡Œæ‰¹é‡è®¡ç®—ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
            # ç¡®ä¿æ‰€æœ‰ç‰¹å¾å‘é‡éƒ½æ˜¯æ­£ç¡®çš„ç»´åº¦ [1, 512]
            embeddings_list = []
            student_ids = []
            
            for student_id, embedding in self._embedding_cache.items():
                # ç¡®ä¿ç»´åº¦æ­£ç¡®
                if embedding.dim() == 3:  # [1, 1, 512]
                    embedding = embedding.squeeze(0)  # å˜æˆ [1, 512]
                elif embedding.dim() == 1:  # [512]
                    embedding = embedding.unsqueeze(0)  # å˜æˆ [1, 512]
                
                # éªŒè¯ç»´åº¦
                if embedding.size(1) == 512:
                    embeddings_list.append(embedding)
                    student_ids.append(student_id)
                else:
                    logger.warning(f"è·³è¿‡ç»´åº¦å¼‚å¸¸çš„ç‰¹å¾å‘é‡: {student_id}, ç»´åº¦: {embedding.size()}")
            
            if not embeddings_list:
                logger.error("æ²¡æœ‰æœ‰æ•ˆçš„ç‰¹å¾å‘é‡ç”¨äºè¯†åˆ«")
                return [(-1, 0.0, {"error": "æ•°æ®åº“ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ç‰¹å¾å‘é‡"})]
            
            embeddings_tensor = torch.cat(embeddings_list, dim=0)  # å˜æˆ [N, 512]
            
            # è°ƒè¯•ä¿¡æ¯
            logger.info(f"ç¼“å­˜ä¸­çš„ç‰¹å¾å‘é‡ç»´åº¦: {embeddings_tensor.size()}")
            logger.info(f"å­¦ç”ŸIDåˆ—è¡¨: {student_ids}")
            
            all_face_results = []
            
            # å¯¹æ¯å¼ äººè„¸è¿›è¡Œè¯†åˆ«
            for face_idx, (test_embedding, quality_result, box, prob) in enumerate(face_results):
                try:
                    # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œäººè„¸åŒ¹é…ï¼ˆæ¯”æ¬§å‡ é‡Œå¾—è·ç¦»æ›´é€‚åˆäººè„¸è¯†åˆ«ï¼‰
                    # ç¡®ä¿ç‰¹å¾å‘é‡ç»´åº¦æ­£ç¡®
                    if test_embedding.dim() == 1:
                        test_embedding = test_embedding.unsqueeze(0)
                    
                    # æ£€æŸ¥ç»´åº¦åŒ¹é…
                    if test_embedding.size(1) != embeddings_tensor.size(1):
                        logger.error(f"ç‰¹å¾å‘é‡ç»´åº¦ä¸åŒ¹é…: æµ‹è¯•å‘é‡ {test_embedding.size()}, æ•°æ®åº“å‘é‡ {embeddings_tensor.size()}")
                        continue
                    
                    # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆæ›´é€‚äºäººè„¸è¯†åˆ«ï¼‰
                    # ç¡®ä¿ç‰¹å¾å‘é‡å·²å½’ä¸€åŒ–
                    test_embedding_normalized = F.normalize(test_embedding, p=2, dim=1)
                    embeddings_normalized = F.normalize(embeddings_tensor, p=2, dim=1)
                    
                    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                    similarities = F.cosine_similarity(test_embedding_normalized, embeddings_normalized, dim=1)
                    
                    # ç¡®ä¿ç›¸ä¼¼åº¦å¼ é‡ç»´åº¦æ­£ç¡®
                    if similarities.size(0) != len(student_ids):
                        logger.error(f"ç›¸ä¼¼åº¦å¼ é‡ç»´åº¦é”™è¯¯: {similarities.size()}, æœŸæœ›: {len(student_ids)}")
                        continue
                    
                    # æ‰¾åˆ°æœ€å¤§ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦è¶Šå¤§è¶Šå¥½ï¼‰
                    max_similarity_idx = torch.argmax(similarities)
                    max_similarity = similarities[max_similarity_idx].item()
                    best_match_student_id = student_ids[max_similarity_idx]
                    
                    # æ„å»ºæ‰€æœ‰ç›¸ä¼¼åº¦å­—å…¸
                    all_similarities = {student_ids[i]: similarities[i].item() for i in range(len(student_ids))}
                    
                    # ç¡®å®šä½¿ç”¨çš„é˜ˆå€¼
                    if use_adaptive_threshold and self.global_threshold is None:
                        threshold = self.face_database.get_adaptive_threshold(best_match_student_id)
                    else:
                        threshold = self.global_threshold or CHILD_CONFIG['recognition']['default_threshold']
                    
                    # åˆ¤æ–­æ˜¯å¦è¯†åˆ«æˆåŠŸï¼ˆåŸºäºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
                    if max_similarity > threshold:
                        recognized_student_id = best_match_student_id
                        confidence = max_similarity  # ç›´æ¥ä½¿ç”¨ç›¸ä¼¼åº¦ä½œä¸ºç½®ä¿¡åº¦
                        # è·å–å­¦ç”Ÿå§“åç”¨äºæ˜¾ç¤º
                        recognized_name = self.face_database.child_profiles[recognized_student_id].name if recognized_student_id in self.face_database.child_profiles else "æœªçŸ¥"
                    else:
                        recognized_student_id = -1
                        recognized_name = "æœªçŸ¥"
                        confidence = 0.0
                    
                    # æ„å»ºè¯¦ç»†ç»“æœ
                    details = {
                        "student_id": recognized_student_id,
                        "name": recognized_name,
                        "similarity": max_similarity,
                        "threshold": threshold,
                        "quality_score": quality_result.quality_score,
                        "all_similarities": all_similarities,
                        "face_size": quality_result.face_size,
                        "recognition_method": "adaptive" if use_adaptive_threshold else "global",
                        "face_index": face_idx + 1,  # äººè„¸ç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼‰
                        "total_faces_detected": len(face_results),
                        "face_confidence": prob,
                        "face_box": box.tolist() if box is not None else None,
                    }
                    
                    if recognized_student_id != -1:
                        # æ·»åŠ å„¿ç«¥æ¡£æ¡ˆä¿¡æ¯
                        if recognized_student_id in self.face_database.child_profiles:
                            profile = self.face_database.child_profiles[recognized_student_id]
                            details["child_info"] = {
                                "student_id": profile.student_id,
                                "name": profile.name,
                                "age": profile.age,
                            }
                    
                    all_face_results.append((recognized_student_id, confidence, details))
                    
                    logger.info(f"äººè„¸ {face_idx+1} è¯†åˆ«ç»“æœ: {recognized_name}({recognized_student_id}) (ç›¸ä¼¼åº¦: {max_similarity:.3f}, ç½®ä¿¡åº¦: {confidence:.3f}, é˜ˆå€¼: {threshold:.3f})")
                    
                except Exception as e:
                    logger.error(f"å¤„ç†äººè„¸ {face_idx+1} æ—¶å‡ºé”™: {e}")
                    all_face_results.append((-1, 0.0, {
                        "error": f"å¤„ç†äººè„¸ {face_idx+1} æ—¶å‡ºé”™: {str(e)}",
                        "face_index": face_idx + 1,
                        "total_faces_detected": len(face_results)
                    }))
            
            logger.info(f"å›¾ç‰‡ {img_path} å…±è¯†åˆ« {len(all_face_results)} å¼ äººè„¸")
            return all_face_results
                
        except Exception as e:
            logger.error(f"è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {img_path}, é”™è¯¯: {e}")
            return [(-1, 0.0, {
                "error": f"è¯†åˆ«è¿‡ç¨‹å¼‚å¸¸: {str(e)}",
                "image_path": img_path
            })]
        finally:
            # å†…å­˜æ¸…ç†
            if 'test_embedding' in locals():
                del test_embedding
            if 'embeddings_tensor' in locals():
                del embeddings_tensor
            torch.cuda.empty_cache() if torch.cuda.is_available() else None

    def recognize_all_faces_batch(self, img_paths: List[str], 
                                 max_workers: int = 4) -> List[List[Tuple[int, float, Dict]]]:
        """
        æ‰¹é‡è¯†åˆ«æ‰€æœ‰å›¾ç‰‡ä¸­çš„æ‰€æœ‰è„¸ï¼ˆå¹¶å‘å¤„ç†ï¼‰
        
        Args:
            img_paths: å¾…è¯†åˆ«å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
            
        Returns:
            List[List[Tuple[int, confidence, details]]]: æ¯å¼ å›¾ç‰‡çš„æ‰€æœ‰äººè„¸è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        if not img_paths:
            return []
        
        results = []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_path = {
                executor.submit(self.recognize_all_faces_in_image, path): path 
                for path in img_paths
            }
            
            for future in future_to_path:
                try:
                    result = future.result(timeout=30)  # 30ç§’è¶…æ—¶
                    results.append(result)
                except Exception as e:
                    path = future_to_path[future]
                    logger.error(f"æ‰¹é‡è¯†åˆ«å¤±è´¥: {path}, é”™è¯¯: {e}")
                    results.append([(-1, 0.0, {"error": str(e)})])
        
        return results
    
    def process_batch_with_individual_params(self, img_paths: List[str], 
                                           class_ids: List[int], 
                                           activity_details: List[str],
                                           is_publics: List[bool],
                                           uploader_ids: List[int],
                                           max_workers: int = 4) -> Dict:
        """
        æ‰¹é‡å¤„ç†å›¾ç‰‡å¹¶å­˜å‚¨åˆ°OSSå’Œæ•°æ®åº“ï¼ˆæ”¯æŒæ¯å¼ å›¾ç‰‡ç‹¬ç«‹å‚æ•°ï¼‰
        
        Args:
            img_paths: å¾…è¯†åˆ«å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            class_ids: æ¯å¼ å›¾ç‰‡å¯¹åº”çš„ç­çº§IDåˆ—è¡¨
            activity_details: æ¯å¼ å›¾ç‰‡å¯¹åº”çš„æ´»åŠ¨è¯¦æƒ…åˆ—è¡¨
            is_publics: æ¯å¼ å›¾ç‰‡å¯¹åº”çš„å…¬å¼€çŠ¶æ€åˆ—è¡¨
            uploader_ids: æ¯å¼ å›¾ç‰‡å¯¹åº”çš„ä¸Šä¼ è€…IDåˆ—è¡¨
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        if not img_paths:
            return {
                'success': False,
                'error': 'æ²¡æœ‰æä¾›å›¾ç‰‡è·¯å¾„'
            }
        
        # éªŒè¯å‚æ•°é•¿åº¦
        if len(img_paths) != len(class_ids) or len(img_paths) != len(activity_details) or \
           len(img_paths) != len(is_publics) or len(img_paths) != len(uploader_ids):
            return {
                'success': False,
                'error': 'å‚æ•°æ•°ç»„é•¿åº¦ä¸åŒ¹é…'
            }
        
        try:
            # 1. æ‰¹é‡è¯†åˆ«æ‰€æœ‰è„¸
            start_time = datetime.now()
            all_faces_results = self.recognize_all_faces_batch(img_paths, max_workers)
            end_time = datetime.now()
            total_processing_time = int((end_time - start_time).total_seconds() * 1000)
            
            # 2. å¤„ç†ç»“æœå¹¶å‡†å¤‡å­˜å‚¨
            processed_results = []
            recognition_records = []
            recognized_count = 0
            session_id = f"batch_{int(datetime.now().timestamp())}"
            
            # å¤„ç†æ¯å¼ å›¾ç‰‡çš„æ‰€æœ‰äººè„¸ç»“æœ
            for i, face_results in enumerate(all_faces_results):
                img_path = img_paths[i]
                class_id = class_ids[i]
                activity_detail = activity_details[i]
                is_public = is_publics[i]
                uploader_id = uploader_ids[i]
                
                # å¤„ç†è¿™å¼ å›¾ç‰‡ä¸­çš„æ‰€æœ‰äººè„¸
                for face_idx, (student_id, confidence, details) in enumerate(face_results):
                    # logger.info(f"debugæ£€æŸ¥ åœ¨process_batch_with_individual_paramsä¸­ å¤„ç†æ¯å¼ å›¾ç‰‡çš„æ‰€æœ‰äººè„¸ç»“æœ: {face_results}")
                    # ç¡®å®šè¯†åˆ«å‡ºçš„å­¦ç”ŸID
                    recognized_child_id = None
                    if student_id != -1: # è¯†åˆ«å‡ºå„¿ç«¥
                        recognized_count += 1
                        recognized_child_id = student_id
                    
                    # å‡†å¤‡è¯†åˆ«è®°å½•
                    record_data = {
                        'test_image_path': img_path,
                        'recognized_child_id': recognized_child_id,
                        'confidence': confidence,
                        'similarity': details.get('similarity', 0),
                        'threshold_used': details.get('threshold', 0),
                        'recognition_method': details.get('recognition_method', 'adaptive'),
                        'face_quality_score': details.get('quality_score', 0),
                        'processing_time_ms': total_processing_time // len(all_faces_results),
                        'session_id': session_id,
                        'face_index': details.get('face_index', face_idx + 1),
                        'class_id': class_id,
                        'activity_detail': activity_detail,
                        'is_public': is_public,
                        'uploader_id': uploader_id
                    }
                    recognition_records.append(record_data)
                    
                    processed_results.append({
                        'image_index': i,
                        'face_index': details.get('face_index', face_idx + 1),
                        'recognized_name': details.get('name', 'æœªçŸ¥'),
                        'student_id': student_id,
                        'confidence': confidence,
                        'is_known_child': student_id != -1,
                        'test_image_path': img_path,
                        'class_id': class_id,
                        'activity_detail': activity_detail,
                        'is_public': is_public,
                        'uploader_id': uploader_id,
                        'details': details
                    })
            
            # 3. ä¸Šä¼ è¯†åˆ«æˆåŠŸçš„å›¾ç‰‡åˆ°OSSå¹¶ä¿å­˜è®°å½•åˆ°æ•°æ®åº“
            saved_records = []
            upload_results = []
            
            if hasattr(self.face_database, 'db_integration') and self.face_database.db_integration:
                try:
                    for record in recognition_records:
                        # ä¸Šä¼ æµ‹è¯•å›¾ç‰‡åˆ°OSSå¹¶ä¿å­˜è¯†åˆ«è®°å½•
                        upload_result = self.face_database.db_integration.upload_recognized_photo(
                            test_image_path=record['test_image_path'],
                            recognized_child_id=record['recognized_child_id'],
                            recognition_confidence=record['confidence'],
                            session_id=session_id,
                            class_id=record['class_id'],
                            activity_detail=record['activity_detail'],
                            is_public=record['is_public'],
                            uploader_id=record['uploader_id']
                        )
                        upload_results.append(upload_result)
                        saved_records.append(upload_result['photo_id'])
                        
                        # æ›´æ–° processed_results ä¸­çš„ test_image_url ä¸ºçœŸå®çš„OSS URL
                        for result in processed_results:
                            if (result['test_image_path'] == record['test_image_path'] and 
                                result['face_index'] == record['face_index']):
                                result['test_image_url'] = upload_result.get('oss_url', record['test_image_path'])
                                break
                    
                    logger.info(f"âœ… æµ‹è¯•å›¾ç‰‡ä¸Šä¼ å’Œè¯†åˆ«è®°å½•ä¿å­˜å®Œæˆ: {len(saved_records)} æ¡è®°å½•")
                except Exception as db_error:
                    logger.warning(f"ä¸Šä¼ æµ‹è¯•å›¾ç‰‡å’Œä¿å­˜è¯†åˆ«è®°å½•å¤±è´¥: {db_error}")
                    # ç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
            
            # è®¡ç®—æ€»äººè„¸æ•°
            total_faces = sum(len(face_results) for face_results in all_faces_results)
            unknown_faces = total_faces - recognized_count
            
            return {
                'success': True,
                'data': {
                    'session_id': session_id,
                    'total_images': len(img_paths),
                    'total_faces_detected': total_faces,
                    'recognized_children': recognized_count,
                    'unknown_faces': unknown_faces,
                    'total_processing_time_ms': total_processing_time,
                    'avg_processing_time_ms': total_processing_time // len(all_faces_results),
                    'results': processed_results,
                    'database_records_saved': len(saved_records),
                    'oss_uploads_completed': len(upload_results),
                    'upload_results': upload_results,
                    'processing_timestamp': datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def get_recognition_statistics(self) -> Dict:
        """è·å–è¯†åˆ«ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "database_size": len(self.face_database.face_embeddings),
            "cache_size": len(self._embedding_cache),
            "last_cache_update": self._last_cache_update.isoformat(),
            "memory_usage": f"{torch.cuda.memory_allocated() / 1024**2:.1f}MB" if torch.cuda.is_available() else "N/A"
        }

    def check_database_status(self) -> Dict:
        """
        æ£€æŸ¥æ•°æ®åº“å’Œç¼“å­˜çŠ¶æ€ï¼Œç”¨äºé—®é¢˜è¯Šæ–­
        
        Returns:
            åŒ…å«æ•°æ®åº“çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
        """
        status = {
            'database_loaded': hasattr(self.face_database, 'face_embeddings'),
            'database_size': len(self.face_database.face_embeddings) if hasattr(self.face_database, 'face_embeddings') else 0,
            'cache_size': len(self._embedding_cache),
            'students_in_database': list(self.face_database.face_embeddings.keys()) if hasattr(self.face_database, 'face_embeddings') else [],
            'students_in_cache': list(self._embedding_cache.keys()),
            'last_cache_update': self._last_cache_update.isoformat() if self._last_cache_update else None
        }
        
        print("ğŸ“Š æ•°æ®åº“çŠ¶æ€æ£€æŸ¥:")
        print(f"   - æ•°æ®åº“æ˜¯å¦åŠ è½½: {status['database_loaded']}")
        print(f"   - æ•°æ®åº“ä¸­å­¦ç”Ÿæ•°é‡: {status['database_size']}")
        print(f"   - ç¼“å­˜ä¸­å­¦ç”Ÿæ•°é‡: {status['cache_size']}")
        print(f"   - æ•°æ®åº“ä¸­çš„å­¦ç”Ÿ: {status['students_in_database']}")
        print(f"   - ç¼“å­˜ä¸­çš„å­¦ç”Ÿ: {status['students_in_cache']}")
        print(f"   - æœ€åç¼“å­˜æ›´æ–°æ—¶é—´: {status['last_cache_update']}")
        
        return status

